{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8f-WoJkTU1o5"
   },
   "source": [
    "# Overview of Hostile Post Detection in Hindi\n",
    "- **Goals:** To predict the label set of the set of post collected from Twitter and facebook.\n",
    "\n",
    "- **Traning data:** post with their label.\n",
    "\n",
    "- **Tesing data:** set of posts.\n",
    "- **Types of post:** \n",
    "1. *Fake News:* A claim or information that is verified to be not true.\n",
    "2. *Hate Speech:* A post targeting a specific group of people based on their ethnicity, religious beliefs, geographical belonging, race, etc., with malicious intentions of spreading hate or encouraging violence.\n",
    "3. *Offensive:* A post containing profanity, impolite, rude, or vulgar language to insult a targeted individual or group.\n",
    "4. *Defamation:* A mis-information regarding an individual or group.\n",
    "5. *Non-hostile:* A post without any hostility.\n",
    "\n",
    "\n",
    "\n",
    "- **dataset.csv:** contains trainng data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIDdsC6QU1o9"
   },
   "source": [
    "## Exploring dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "y7HpR5wZU1o-"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must provide an even number of non-keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1e4c2ad4f75f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_colwidth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__func__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_set_option\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mnargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mnargs\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Must provide an even number of non-keyword arguments\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;31m# default to false\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must provide an even number of non-keyword arguments"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import pandas as pd     \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUt4QAhXU1pA"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many posts do we have in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "45rtWWwZU1pD",
    "outputId": "bc6df1e9-9a1b-417d-995e-e5df931cc021"
   },
   "outputs": [],
   "source": [
    "print(\"We have\", data.shape[0], \"posts in the training set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First and last five posts of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "yorlo8vIU1pH",
    "outputId": "d99a370c-a07c-4c61-f6c5-e85e7e65d841"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "LBjtXf6CVsBp",
    "outputId": "dd051ee8-53db-41b5-db36-66e5e94e4641"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information about the attributes and tupples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "id": "K0nEa0QLU1pJ",
    "outputId": "83a0c220-f70f-41b4-b35e-fd84d23778da"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### removing extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cuusc2RuU1pM"
   },
   "outputs": [],
   "source": [
    "data=data.drop(data.columns[[0,3,4]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New information of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "id": "NLO9o5MpU1pP",
    "outputId": "d1d6e10a-2d79-41ef-aeda-9b5f28709da0"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "da8yvF7jU1pR",
    "outputId": "a1b54760-70e9-4e44-e025-857e8748458f"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "IFRAZ75BU1pU",
    "outputId": "02134fbe-b8f5-447f-9ef8-7ebd5dabf9a7"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the null values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "id": "k4NQUDcHU1pW",
    "outputId": "9b3ea895-fc04-444e-e4e6-71f08cae4333"
   },
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IeEtVtaYi7Tk"
   },
   "source": [
    "#### Number of columns and rows in train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UrpjElybibvK",
    "outputId": "cabbf91c-d579-4f96-f2b2-43659b538766"
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "print(data.shape,\"is the dimension of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMUZ2jXZmkmR"
   },
   "source": [
    "#### Checking for the duplicates in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data['Post'])-len(set(data['Post'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating the number and percentage of different types of post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "ZLxcrMXpWk8Y",
    "outputId": "d0dbcfee-d3e3-4ace-b775-b6cabaf6cd50",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d={}\n",
    "total=0\n",
    "for i in data['Labels Set']:\n",
    "    ar=list(i.split(','))\n",
    "    for j in ar:\n",
    "        try:\n",
    "            d[j]+=1\n",
    "        except:\n",
    "            d[j]=1\n",
    "        total+=1\n",
    "\n",
    "\n",
    "percentageHolder={}\n",
    "for i in d:\n",
    "    percentageHolder[i]=str((d[i]/total)*100)[:5]+'%'\n",
    "\n",
    "\n",
    "\n",
    "table={'count':d,'percentage':percentageHolder}\n",
    "print(pd.DataFrame(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Represntation of label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "sbCPQocVU1pZ",
    "outputId": "ac082a34-8536-4ce8-917f-6a57d802bcb0"
   },
   "outputs": [],
   "source": [
    "#pie chart creation\n",
    "\n",
    "labels = list(d.keys())\n",
    "values = list(d.values())\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(values, labels=labels,autopct=\"%1.2f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "\n",
    "Data is biased towards non-hostile post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "eqzu6pkKpD4H",
    "outputId": "684775c9-1446-495a-aa63-56284337b084"
   },
   "outputs": [],
   "source": [
    "# Bar Plot\n",
    "plt.bar(d.keys(), d.values(), 0.6, color=['g','g','r','g','g'])\n",
    "plt.xlabel(\"Labels\", labelpad=14)\n",
    "plt.ylabel(\"Frequency\", labelpad=14)\n",
    "sb.set(font_scale=1.4)\n",
    "plt.xticks(fontsize=14, rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQ5Y6zW_U1pb"
   },
   "source": [
    "Analysis:\n",
    "\n",
    "1) We observe that non-hostile posts has the highest proportion i.e more than 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if the duplicate posts have duplicate labels or not\n",
    "\n",
    "temp=set()\n",
    "d={}\n",
    "index=0\n",
    "for i in data['Post']:\n",
    "    if i not in temp:\n",
    "        temp.add(i)\n",
    "        d[i]=[[data['Labels Set'][index],index]]\n",
    "    else:\n",
    "        d[i].append([data['Labels Set'][index],index])\n",
    "        print(d[i])\n",
    "    index+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing duplicate rows\n",
    "\n",
    "postTemp={'Post':[],'Labels Set':[]}\n",
    "visited=set()\n",
    "index=0\n",
    "\n",
    "for i in data['Post']:\n",
    "    if i not in visited and index!=4970:\n",
    "        postTemp['Post'].append(i)\n",
    "        postTemp['Labels Set'].append(data['Labels Set'][index])\n",
    "        visited.add(i)\n",
    "    index+=1\n",
    "        \n",
    "data=pd.DataFrame.from_dict(postTemp)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing urls & mentions from the string\n",
    "\n",
    "data['Post'] = data['Post'].str.replace('http\\S+|www.\\S+|@\\S+', '', case=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating Hashtags\n",
    "ht=[]\n",
    "\n",
    "\n",
    "for i in data['Post']:\n",
    "    temp=[]\n",
    "    start=0\n",
    "    for j in i:\n",
    "        if j=='#':\n",
    "            start=1\n",
    "            holder=''\n",
    "        if j==' ' and start:\n",
    "            start=0\n",
    "            temp.append(holder)\n",
    "            \n",
    "        elif start==1:\n",
    "            holder+=j\n",
    "    ht.append(temp)\n",
    "            \n",
    "data['Hashtag']=ht\n",
    "\n",
    "data['Post'] = data['Post'].str.replace('#\\S+', '', case=False)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing Punctuations\n",
    "\n",
    "f=open(\"punctuations.txt\",\"r\")\n",
    "punctuations=set(f.read().split('\\n'))\n",
    "index=0\n",
    "\n",
    "for i in data['Post']:\n",
    "    temp=''\n",
    "    for j in i:\n",
    "        if j not in punctuations:\n",
    "            temp+=j\n",
    "        else:\n",
    "            temp+=' '\n",
    "    data['Post'][index]=temp\n",
    "    index+=1\n",
    "    \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words \n",
    "\n",
    "f=open(\"stopWords.txt\",\"r\")\n",
    "stopWords=set(f.read().split('\\n'))\n",
    "\n",
    "index=0\n",
    "\n",
    "for i in data['Post']:\n",
    "    temp=''\n",
    "    words=i.split(' ')\n",
    "    for j in words:\n",
    "        if j not in stopWords:\n",
    "            temp+=j\n",
    "            temp+=' '\n",
    "    data['Post'][index]=temp\n",
    "    index+=1\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating emojis\n",
    "\n",
    "emojis=[]\n",
    "index=0\n",
    "\n",
    "for i in data['Post']:\n",
    "    post=\"\"\n",
    "    temp=[]\n",
    "    for j in i:\n",
    "        if (u'\\u0900' <= j <= u'\\u097f' or j==' ' or j.isdigit() or j=='\\n' or j.isalpha()):\n",
    "            post+=j\n",
    "        else:\n",
    "            temp.append(j)\n",
    "    emojis.append(temp)\n",
    "    data['Post'][index]=post\n",
    "    index=0\n",
    "    \n",
    "data['emojis']=emojis\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#english specific preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translating hindi to english using \"googletrans\" API\n",
    "# import time\n",
    "# errorCounter=0\n",
    "# cnt=0\n",
    "# eng=[]\n",
    "# f = open(\"res.txt\", \"a\")\n",
    "# f.write(\"Now the file has more content!\")\n",
    "# for i in range(5728):\n",
    "#     t=Translator()\n",
    "#     cnt+=1\n",
    "#     time.sleep(1)\n",
    "    \n",
    "#     print(cnt,errorCounter)\n",
    "#     # if i%5==0:\n",
    "#     #     time.sleep(1)\n",
    "#     try:\n",
    "#         f.write(t.translate(translationInput[i]).text)\n",
    "#         f.write('\\n')\n",
    "#     except:\n",
    "#         errorCounter+=1\n",
    "# print(\"Total Loss = \" + str(errorCounter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercasing \n",
    "\n",
    "f = open(\"res.txt\", \"r\")\n",
    "englishPost=list(f.read().split('\\n'))\n",
    "\n",
    "for i in range(len(englishPost)):\n",
    "    englishPost[i]=englishPost[i].lower()\n",
    "\n",
    "englishPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming\n",
    "\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import word_tokenize \n",
    "   \n",
    "ps = PorterStemmer()\n",
    "index=0\n",
    "\n",
    "for i in englishPost:\n",
    "    sentence=''\n",
    "    for word in i:\n",
    "        sentence+=ps.stem(word)\n",
    "    englishPost[index]=sentence\n",
    "    index+=0\n",
    "    \n",
    "englishPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stop words from english\n",
    "\n",
    "f=open(\"punctuations.txt\",\"r\")\n",
    "stopWordsEnglish=set(f.read().split('\\n'))\n",
    "\n",
    "index=0\n",
    "\n",
    "for i in englishPost:\n",
    "    words=i.split(' ')\n",
    "    sentence=''\n",
    "    for word in words:\n",
    "        if word not in stopWordsEnglish:\n",
    "            sentence+=word\n",
    "    englishPost[index]=sentence\n",
    "    index=0\n",
    "\n",
    "englishPost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "D(18).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
